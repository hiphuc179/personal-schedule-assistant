import json
import os
import re
import unicodedata

class LocationParser:
    def __init__(self):
        # 1. LOAD D·ªÆ LI·ªÜU
        base_dir = os.path.dirname(os.path.abspath(__file__))
        data_path = os.path.join(base_dir, "data", "locations.json")
        
        self.locations_db = {}
        if os.path.exists(data_path):
            with open(data_path, "r", encoding="utf-8") as f:
                self.locations_db = json.load(f)
        
        # 2. STOP VERBS (ƒê·ªông t·ª´ c·∫•m - G·∫∑p l√† C·∫ÆT ƒêU√îI)
        self.stop_verbs = [
            "mua", "b√°n", "thu√™", "ƒÉn", "u·ªëng", "ch∆°i", "ng·ªß", "ngh·ªâ", 
            "t·∫Øm", "v·ªá", "h·ªçc", "l√†m", "ki·∫øm", "qu·∫©y", "ƒëi", 
            "ƒë√°", "t·∫≠p", "xem", "s·ª≠a", "kh√°m", "ch·ªØa", "tuy·ªÉn",
            "thƒÉm", "ƒë√≥n", "r∆∞·ªõc", "g·∫∑p", "ch·ªù", "ƒë·ª£i", "l·∫•y", "n·ªôp",
            "ƒë√¥ng", "gi·∫£m", "h√≥ng", "r√∫t", "k·∫πt", "thi", "l·ªôi", "check",
            "ch·ª•p", "h√¨nh", "phim", "·∫£nh", "coi", "nh√¨n", "th·∫•y",
            "qu√°", "t·∫£i", "l·∫Øm", "nh∆∞", "l√†", "c·ªßa",
            "tr√°nh", "ch·∫°y", "h√°t", "h√≤", "ƒë√°nh", "t√¨m", "c·∫•t",
            "la", "m·∫Øng", "ch·ª≠i", "v√†o", "ra", "l√™n", "xu·ªëng",
            "bi·∫øt", "hi·ªÉu", "d√°m", "th√®m", "∆∞a", "ng√°n", "nh·ªõ", "qu√™n",
            "g·ª≠i", "b∆°i", "gi·ªØ" 
        ]
        
        # 3. BLACKLIST (C·ª•m t·ª´ r√°c)
        # 3. BLACKLIST (C·ª•m t·ª´ r√°c & ƒê·ªäA ƒêI·ªÇM ·∫¢O)
        # [UPDATE] ƒê√£ th√™m: c√¥ng t√°c, du l·ªãch, tham quan...
       # 3. BLACKLIST (C·ª•m t·ª´ r√°c)
        self.black_list = [
            "ng·ªß th√¥i", "ch∆°i nh√©", "ngh·ªâ ng∆°i", "v·ªá sinh",
            "l√†m vi·ªác", "h·ªçc b√†i", "t·∫Øm r·ª≠a", "ki·∫øm ti·ªÅn", "ƒë√¢u ƒë√≥", 
            "ƒë√¢u", "nh√©", "nha", "th√¥i", "lu√¥n", "r·ªìi", "ngay",
            "m·∫°ng", "l√≤ng", "v·∫ª", "ƒë·ªì", "m∆°", "vi·ªác", "chuy·ªán", "ng∆∞·ªùi",
            "l√™n m·∫°ng", "trong l√≤ng", "ra v·∫ª", "l√™n ƒë·ªì", "trong m∆°", "v√†o vi·ªác",
            "ta ƒë√¢y", "ng∆∞·ªùi h√¢m m·ªô", "qua loa",
            "c√¥ng t√°c", "du l·ªãch", "ph∆∞·ª£t", "tham quan", "d√£ ngo·∫°i",
            "b·ªô", "bu·ªïi" # <--- TH√äM 'bu·ªïi' V√ÄO ƒê√ÇY
        ]
        
    # --- H√ÄM 1: L·ªåC TH·ªúI GIAN ---
    def _is_time_expression(self, text):
        text = text.lower().strip()
        if re.search(r'\d+\s*(h|g|:|p|ph√∫t|gi√¢y|ti·∫øng|am|pm)', text): return True
        if re.search(r'(?:th·ª©\s+\d|th·ª©\s+hai|th·ª©\s+ba|ch·ªß nh·∫≠t|h√¥m\s+nay|ng√†y\s+mai|m·ªët|tu·∫ßn)', text): return True
        if text in ["gi·ªù", "ph√∫t", "gi√¢y", "h√¥m nay", "b√¢y gi·ªù", "l√∫c n√£y", "ban n√£y"]:
            return True
        if text.isdigit(): return True
        return False

    # --- H√ÄM 2: QU√âT T·ª™ ƒêI·ªÇN ---
    def _scan_dictionary(self, text):
        found = []
        all_places = []
        for key in self.locations_db:
            all_places.extend(self.locations_db[key])
        all_places.sort(key=len, reverse=True)
        
        for place in all_places:
            if re.search(r'\b' + re.escape(place) + r'\b', text, re.IGNORECASE):
                found.append(place)
        return found

    # --- H√ÄM 3: QU√âT REGEX & C·∫ÆT ƒêU√îI ---
    def _scan_by_regex(self, text):
        # T·ª´ kh√≥a m·ªü ƒë·∫ßu
        prepositions = r"(?:t·∫°i|·ªü|ƒë·∫øn|v·ªÅ|gh√©|ra|trong|tr√™n|t·ªõi|l√™n|xu·ªëng|v√†o)"
        # Danh t·ª´ ƒë·ªãa ƒëi·ªÉm
        location_nouns = r"(?:khu vui ch∆°i|trung t√¢m th∆∞∆°ng m·∫°i|b√£i g·ª≠i xe|b√£i gi·ªØ xe|h·ªì b∆°i|s√¢n|qu√°n|ch·ª£|si√™u th·ªã|tr∆∞·ªùng|c√¥ng vi√™n|nh√†|b·ªánh vi·ªán|cƒÉn h·ªô|chung c∆∞|ti·ªám|shop|trung t√¢m|h·ªì|b√£i|khu|ph√≤ng)"
        
        # --- [FIX QUAN TR·ªåNG] T·ª™ KH√ìA K·∫æT TH√öC ---
        # Th√™m: kh√¥ng, ko, ch∆∞a, b·∫°n, anh, em, ch·ªã, nh·ªâ, h·∫£, d·∫•u h·ªèi...
        stop_list = r"bu·ªïi|l√∫c|v√†o|ng√†y|trong|h√¥m|s√°ng|tr∆∞a|chi·ªÅu|t·ªëi|mai|m·ªët|kia|tu·∫ßn|th√°ng|nƒÉm|c√°i|l·∫≠n|n√®|lu√¥n|kh√¥ng|ko|ch∆∞a|b·∫°n|anh|ch·ªã|em|nh·ªâ|h·∫£|nh√°|b·ªô|\?"
        
        found = []
        
        # Pattern A: Gi·ªõi t·ª´ + N·ªôi dung
        pat_prep = f"{prepositions}\s+(.*?)(?=\s(?:{stop_list})|$)"
        found.extend(re.findall(pat_prep, text, re.IGNORECASE))

        # Pattern B: Danh t·ª´ + N·ªôi dung
        pat_noun = f"(?:^|\s)({location_nouns}\s*.*?)(?=\s(?:{stop_list})|$)"
        found.extend(re.findall(pat_noun, text, re.IGNORECASE))

        clean_found = []
        for loc in found:
            # X√≥a d·∫•u c√¢u th·ª´a ·ªü cu·ªëi (VD: qu·∫≠n 9?)
            loc = loc.strip(" ?.!,")
            
            # 1. L·ªçc Time
            if self._is_time_expression(loc): continue

            words = loc.split()
            if not words: continue

            # 2. Check t·ª´ ƒë·∫ßu ti√™n
            if words[0].lower() in self.stop_verbs: continue

            # 3. C·∫Øt ƒëu√¥i h√†nh ƒë·ªông
            valid_words = []
            for i, word in enumerate(words):
                w = word.lower()
                if w in self.stop_verbs:
                    # --- NGO·∫†I L·ªÜ ---
                    prev = words[i-1].lower() if i > 0 else ""
                    if ((w == "g·ª≠i" or w == "gi·ªØ") and prev == "b√£i"):
                        valid_words.append(word); continue
                    if (w == "b∆°i" and prev == "h·ªì"):
                        valid_words.append(word); continue
                    if (w == "ch∆°i" and prev == "vui"):
                        valid_words.append(word); continue
                    break # C·∫ÆT
                valid_words.append(word)
            
            if not valid_words: continue
            final_loc = " ".join(valid_words).strip()
            
            if len(final_loc) < 2 or final_loc.isdigit(): continue
            if self._is_time_expression(final_loc): continue

            # 4. Check Blacklist
            is_blacklisted = False
            for bad_word in self.black_list:
                if re.search(r'\b' + re.escape(bad_word) + r'\b', final_loc.lower()):
                     is_blacklisted = True; break
            if is_blacklisted: continue

            # 5. D·ªçn r√°c
            final_loc = re.sub(r'^(nh√†|qu√™)\s+(·ªü|t·∫°i)\s+', '', final_loc, flags=re.IGNORECASE)
            final_loc = re.sub(r'^(c√°i|ng√¥i|chi·∫øc)\s+', '', final_loc, flags=re.IGNORECASE)
            
            clean_found.append(final_loc)
                
        return clean_found

    # --- H√ÄM 4: EXTRACT CH√çNH ---
    def extract(self, text):
        regex_locs = self._scan_by_regex(text)
        dict_locs = self._scan_dictionary(text)
        candidates = regex_locs + dict_locs
        return max(candidates, key=len) if candidates else None

# --- TEST ---
if __name__ == "__main__":
    parser = LocationParser()
    print("\nüöÄ TEST FINAL V15...")
    test_cases = [
        "t·ªëi mai c√≥ vi·ªác ƒëi qu·∫≠n 9 kh√¥ng b·∫°n?", # -> qu·∫≠n 9 (C·∫Øt 'kh√¥ng b·∫°n?')
        "ƒëi ƒë√¢u ƒë√≥ ch∆°i ƒëi",                    # -> ---
        "cƒÉn h·ªô landmark 81",       
        "m·ªói tu·∫ßn ƒë·ªÅu ƒëi b·ªô bu·ªïi s√°ng",
    ]
    for text in test_cases:
        loc = parser.extract(text)
        print(f"{text:<40} | {str(loc) if loc else '---'}")