import json
import os
import re
import unicodedata
try:
    from underthesea import word_tokenize
    HAS_UNDERTHESEA = True
except ImportError:
    HAS_UNDERTHESEA = False
    print("âš ï¸ Cáº£nh bÃ¡o: ChÆ°a cÃ i 'underthesea'. Äang cháº¡y cháº¿ Ä‘á»™ Rule-based thuáº§n tÃºy.")
class Preprocessor:
    def __init__(self):
        # XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n file data
        base_dir = os.path.dirname(os.path.abspath(__file__))
        data_dir = os.path.join(base_dir, "data")
        
        # 1. LOAD TEENCODE (replace_dict.json)
        self.replace_dict = {}
        path_replace = os.path.join(data_dir, "replace_dict.json")
        if os.path.exists(path_replace):
            with open(path_replace, "r", encoding="utf-8") as f:
                self.replace_dict = json.load(f)
        
        # 2. LOAD ANH-VIá»†T (en_vi.json)
        self.en_vi_dict = {}
        path_en_vi = os.path.join(data_dir, "en_vi.json")
        if os.path.exists(path_en_vi):
            with open(path_en_vi, "r", encoding="utf-8") as f:
                self.en_vi_dict = json.load(f)

        # 3. LOAD IGNORE WORDS (Cho cÃ³, chá»© file nÃ y khÃ´ng dÃ¹ng Ä‘á»ƒ xÃ³a tá»«)
        self.ignore_words = []
        path_ignore = os.path.join(data_dir, "ignore_words.json")
        if os.path.exists(path_ignore):
            with open(path_ignore, "r", encoding="utf-8") as f:
                self.ignore_words = json.load(f)

    def _basic_normalize(self, text):
        if not text: return ""
        # Chuyá»ƒn vá» chá»¯ thÆ°á»ng vÃ  chuáº©n hÃ³a Unicode
        return unicodedata.normalize("NFC", text.lower())
    def _nlp_segmentation(self, text):
        """
        [HYBRID] Sá»­ dá»¥ng mÃ´ hÃ¬nh AI (Underthesea) Ä‘á»ƒ tÃ¡ch tá»«.
        VD: "thá»±c hiá»‡n" -> "thá»±c_hiá»‡n" (giÃºp mÃ¡y hiá»ƒu lÃ  1 tá»«)
        Tuy nhiÃªn, Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i Regex cÅ©, ta sáº½ join láº¡i báº±ng khoáº£ng tráº¯ng.
        Má»¥c Ä‘Ã­ch chÃ­nh: Chuáº©n hÃ³a khoáº£ng cÃ¡ch giá»¯a cÃ¡c tá»«.
        """
        if HAS_UNDERTHESEA:
            try:
                # word_tokenize tráº£ vá» list: ['hÃ´m_nay', 'tÃ´i', 'Ä‘i', 'há»c']
                # Ta join láº¡i vÃ  thay _ báº±ng khoáº£ng tráº¯ng Ä‘á»ƒ khá»›p vá»›i Regex cÅ©
                tokens = word_tokenize(text)
                text = " ".join(tokens).replace("_", " ")
            except Exception:
                pass # Náº¿u lá»—i model thÃ¬ bá» qua, dÃ¹ng text gá»‘c
        return text
    def _process_context_rules(self, text):
            """
            Xá»­ lÃ½ ngá»¯ cáº£nh thÃ´ng minh cho tá»« Ä‘a nghÄ©a (VD: 'hn')
            """
            # 1. HN -> HÃ  Ná»™i (náº¿u Ä‘á»©ng sau giá»›i tá»« chá»‰ Ä‘á»‹a Ä‘iá»ƒm)
            # VD: á»Ÿ hn, vá» hn, Ä‘áº¿n hn -> á»Ÿ hÃ  ná»™i, vá» hÃ  ná»™i
            text = re.sub(r'\b(á»Ÿ|táº¡i|vá»|Ä‘áº¿n|ghÃ©|ra|trong|Ä‘i|tá»›i)\s+hn\b', r'\1 hÃ  ná»™i', text)
            
            # 2. HN -> HÃ´m nay (cÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i)
            # VD: hn tÃ´i Ä‘i há»c -> hÃ´m nay tÃ´i Ä‘i há»c
            text = re.sub(r'\bhn\b', 'hÃ´m nay', text)
            
            return text
    def _translate_en_vi(self, text):
        """Dá»‹ch Anh -> Viá»‡t"""
        if not self.en_vi_dict: return text
        
        # Sáº¯p xáº¿p tá»« dÃ i lÃªn trÆ°á»›c
        sorted_keys = sorted(self.en_vi_dict.keys(), key=len, reverse=True)
        for key in sorted_keys:
            pattern = r'\b' + re.escape(key) + r'\b'
            text = re.sub(pattern, self.en_vi_dict[key], text)
        return text

    def _replace_phrases(self, text):
        """Dá»‹ch Teencode -> Viá»‡t"""
        if not self.replace_dict: return text
        
        sorted_keys = sorted(self.replace_dict.keys(), key=len, reverse=True)
        for key in sorted_keys:
            pattern = r'\b' + re.escape(key) + r'\b'
            text = re.sub(pattern, self.replace_dict[key], text)
        return text
    
    

    def process(self, text):
        # B1: Chuáº©n hÃ³a
        text = self._basic_normalize(text)
        
        # B2: Xá»­ lÃ½ ngá»¯ cáº£nh thÃ´ng minh (CHáº Y TRÆ¯á»šC Tá»ª ÄIá»‚N Cá»¨NG)
        text = self._process_context_rules(text)
        
        # B3: Dá»‹ch Anh -> Viá»‡t
        text = self._translate_en_vi(text)
        
        # B4: Dá»‹ch Teencode cÃ²n láº¡i
        text = self._replace_phrases(text)
        
        # B5: Dá»n rÃ¡c
        text = re.sub(r'\s+', ' ', text).strip()
        return text

# --- PHáº¦N TEST Tá»”NG Há»¢P (Copy Ä‘Ã¨ vÃ o cuá»‘i file nlp/preprocessor.py) ---
if __name__ == "__main__":
    p = Preprocessor()
    
    print("\n" + "="*80)
    print(f"ðŸš€ TRáº NG THÃI Há»† THá»NG:")
    print(f"- Teencode loaded: {len(p.replace_dict)} tá»«")
    print(f"- En-Vi loaded:    {len(p.en_vi_dict)} tá»«")
    print(f"- Ignore loaded:   {len(p.ignore_words)} tá»«")
    print("="*80 + "\n")

    test_suite = {
        # --- NHÃ“M 1: KIá»‚M TRA NGá»® Cáº¢NH "HN" (HÃ  Ná»™i vs HÃ´m Nay) ---
        "TEST CONTEXT HN": [
            "hn tui Ä‘i cÃ´ng tÃ¡c",               # hn Ä‘á»©ng Ä‘áº§u -> hÃ´m nay
            "tá»‘i hn ráº£nh ko",                   # hn Ä‘á»©ng sau thá»i gian -> hÃ´m nay
            "nhÃ  t á»Ÿ hn nha",                   # sau 'á»Ÿ' -> hÃ  ná»™i
            "mai vá» hn Äƒn táº¿t",                 # sau 'vá»' -> hÃ  ná»™i
            "ghÃ© hn chÆ¡i xÃ­u",                  # sau 'ghÃ©' -> hÃ  ná»™i
            "hn mÆ°a to á»Ÿ hn",                   # Combo: hÃ´m nay ... hÃ  ná»™i
            "táº¡i hn Ä‘ang káº¹t xe",               # sau 'táº¡i' -> hÃ  ná»™i
            "hn b Ä‘i Ä‘Ã¢u",                      # hÃ´m nay
        ],
        
        # --- NHÃ“M 2: KIá»‚M TRA MÆ¯A / MUA / TRÃ”I / TRá»œI ---
        "TEST MÆ¯A/MUA/TRÃ”I": [
            "hn Ä‘ang mua to láº¯m",               # mua to -> mÆ°a to
            "sg Ä‘ang dang mua",                 # dang mua -> Ä‘ang mÆ°a
            "Ä‘i siÃªu thá»‹ mua Ä‘á»“",               # mua Ä‘á»“ -> giá»¯ nguyÃªn (khÃ´ng Ä‘á»•i thÃ nh mÆ°a)
            "mua 3kg tÃ¡o",                      # mua -> giá»¯ nguyÃªn
            "thá»i gian troi qua mau",           # troi qua -> trÃ´i qua
            "náº¯ng quÃ¡ tr quÃ¡ Ä‘áº¥t",              # tr -> trá»i
        ],

        # --- NHÃ“M 3: ANH - VIá»†T & CÃ”NG VIá»†C ---
        "TEST ENGLISH": [
            "set cÃ¡i meeting gáº¥p",              # set -> thiáº¿t láº­p, meeting -> cuá»™c há»p
            "boss confirm chÆ°a",                # boss -> sáº¿p, confirm -> xÃ¡c nháº­n
            "deadline dÃ­ sáº¥p máº·t",              # deadline -> giá»¯ nguyÃªn
            "gá»­i file report cho manager",      # file giá»¯ nguyÃªn, manager -> quáº£n lÃ½
            "check mail dÃ¹m t",                 # mail giá»¯ nguyÃªn
            "m doc cuon book nÃ y chua",         # doc -> Ä‘á»c, book -> sÃ¡ch, cuon -> cuá»‘n
        ],

        # --- NHÃ“M 4: KHÃ”NG Dáº¤U & TEENCODE KHÃ“ ---
        "TEST KHÃ”NG Dáº¤U": [
            "hn toi Co ChUyen ConG TaC",        # toi->tÃ´i, co->cÃ³, chuyen->chuyáº¿n, cong tac->cÃ´ng tÃ¡c
            "r h 2 b s r da Vai S tRoi qua",    # vai s -> vÃ i giÃ¢y, troi qua -> trÃ´i qua
            "lam viec met qua",                 # lam->lÃ m, met->má»‡t (náº¿u cÃ³ trong dict)
            "ko dc dau nha",                    # ko->khÃ´ng, dc->Ä‘Æ°á»£c
            "uhm thui ke di",                   # thui->thÃ´i
        ],

        # --- NHÃ“M 5: Äá»ŠA ÄIá»‚M & Há»–N Há»¢P ---
        "TEST MIX": [
            "Ä‘i vt cÃ¹ng nhom",                  # vt->vÅ©ng tÃ u, nhom->nhÃ³m
            "ghÃ© dn Äƒn mÃ¬ quáº£ng",               # dn->Ä‘Ã  náºµng
            "ra q7 ngáº¯m cáº£nh",                  # q7->quáº­n 7
            "tp hcm káº¹t xe vch",                # tp hcm->thÃ nh phá»‘ há»“ chÃ­ minh, vch->vÃ£i chÆ°á»Ÿng
            "háº¹n t2 tuáº§n sau 9h sÃ¡ng",          # t2->thá»© hai, 9h giá»¯ nguyÃªn
            "cn nÃ y ráº£nh ko",                   # cn->chá»§ nháº­t
             "toi nay 7h ranh ko",
        ]
    }

    print(f"{'INPUT':<40} | {'OUTPUT (Káº¿t quáº£ xá»­ lÃ½)':<50}")
    print("-" * 95)
    
    for category, cases in test_suite.items():
        print(f"--- {category} ---")
        for text in cases:
            output = p.process(text)
            print(f"{text:<40} | {output}")
        print("-" * 95)